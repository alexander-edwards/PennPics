{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# This code incorporates lots of the code from the AWS tutorial https://www.youtube.com/watch?v=KCzgR7eQ3PY\n",
    "# Database generated through the react app from https://github.com/gabehollombe-aws/webcam-sagemaker-inference\n",
    "# \n",
    "\n",
    "\n",
    "# An S3 Bucket Name\n",
    "data_bucket_name='webcam-s3-uploaderc98413fa7dc14dd280ab0b913fd2b0ec-data'\n",
    "\n",
    "# A prefix name inside the S3 bucket containing sub-folders of images (one per label class)\n",
    "dataset_name = 'FinalData'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BASE_DIR=/tmp\n",
      "env: S3_DATA_BUCKET_NAME=webcam-s3-uploaderc98413fa7dc14dd280ab0b913fd2b0ec-data\n",
      "env: DATASET_NAME=FinalData\n",
      "env: IM2REC=/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/tools/im2rec.py\n"
     ]
    }
   ],
   "source": [
    "# Find im2rec in our environment and set up some other vars in our environemnt\n",
    "\n",
    "base_dir='/tmp'\n",
    "\n",
    "%env BASE_DIR=$base_dir\n",
    "%env S3_DATA_BUCKET_NAME = $data_bucket_name\n",
    "%env DATASET_NAME = $dataset_name\n",
    "\n",
    "import sys,os\n",
    "\n",
    "suffix='/mxnet/tools/im2rec.py'\n",
    "im2rec = list(filter( (lambda x: os.path.isfile(x + suffix )), sys.path))[0] + suffix\n",
    "%env IM2REC=$im2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull our images from S3\n",
    "!aws s3 sync s3://$S3_DATA_BUCKET_NAME/public/$DATASET_NAME $BASE_DIR/$DATASET_NAME --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LST files\n",
      "Label classes:\n",
      "Bottle 0\n",
      "Can 1\n",
      "None 2\n",
      "test1 3\n",
      "Creating RecordIO files\n",
      "Creating .rec file from /tmp/FinalData_train.lst in /tmp\n",
      "time: 0.005462646484375  count: 0\n",
      "Creating .rec file from /tmp/FinalData_test.lst in /tmp\n",
      "time: 0.002257823944091797  count: 0\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 459K Sep  8 12:29 FinalData_test.rec\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 1.1M Sep  8 12:29 FinalData_train.rec\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use the IM2REC script to convert our images into RecordIO files\n",
    "\n",
    "# Clean up our working dir of existing LST and REC files\n",
    "cd $BASE_DIR\n",
    "rm *.rec\n",
    "rm *.lst\n",
    "\n",
    "# First we need to create two LST files (training and test lists), noting the correct label class for each image\n",
    "# We'll also save the output of the LST files command, since it includes a list of all of our label classes\n",
    "echo \"Creating LST files\"\n",
    "python $IM2REC --list --recursive --pass-through --test-ratio=0.3 --train-ratio=0.7 $DATASET_NAME $DATASET_NAME > ${DATASET_NAME}_classes\n",
    "\n",
    "echo \"Label classes:\"\n",
    "cat ${DATASET_NAME}_classes\n",
    "\n",
    "# Then we create RecordIO files from the LST files\n",
    "echo \"Creating RecordIO files\"\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_train.lst $DATASET_NAME\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\n",
    "ls -lh *.rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../../tmp/FinalData_train.rec to s3://sagemaker-us-east-2-425359244402/FinalData/train/FinalData_train.rec\n",
      "upload: ../../../tmp/FinalData_test.rec to s3://sagemaker-us-east-2-425359244402/FinalData/validation/FinalData_test.rec\n"
     ]
    }
   ],
   "source": [
    "# Upload our train and test RecordIO files to S3 in the bucket that our sagemaker session is using\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "s3train_path = 's3://{}/{}/train/'.format(bucket, dataset_name)\n",
    "s3validation_path = 's3://{}/{}/validation/'.format(bucket, dataset_name)\n",
    "\n",
    "# Clean up any existing data\n",
    "!aws s3 rm s3://{bucket}/{dataset_name}/train --recursive\n",
    "!aws s3 rm s3://{bucket}/{dataset_name}/validation --recursive\n",
    "\n",
    "# Upload the rec files to the train and validation channels\n",
    "!aws s3 cp /tmp/{dataset_name}_train.rec $s3train_path\n",
    "!aws s3 cp /tmp/{dataset_name}_test.rec $s3validation_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(\n",
    "    s3train_path, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='application/x-recordio', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(\n",
    "    s3validation_path, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='application/x-recordio', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, dataset_name)\n",
    "\n",
    "image_classifier = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role, \n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.p2.xlarge',\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_pretrained_model': 1,\n",
       " 'image_shape': '3,224,224',\n",
       " 'num_classes': 4,\n",
       " 'num_training_samples': 63,\n",
       " 'learning_rate': 0.001,\n",
       " 'mini_batch_size': 5}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=! ls -l {base_dir}/{dataset_name} | wc -l\n",
    "num_classes=int(num_classes[0]) - 1\n",
    "\n",
    "num_training_samples=! cat {base_dir}/{dataset_name}_train.lst | wc -l\n",
    "num_training_samples = int(num_training_samples[0])\n",
    "\n",
    "# Learn more about the Sagemaker built-in Image Classifier hyperparameters here: https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html\n",
    "\n",
    "# These hyperparameters we won't want to change, as they define things like\n",
    "# the size of the images we'll be sending for input, the number of training classes we have, etc.\n",
    "base_hyperparameters=dict(\n",
    "    use_pretrained_model=1,\n",
    "    image_shape='3,224,224',\n",
    "    num_classes=num_classes,\n",
    "    num_training_samples=num_training_samples,\n",
    ")\n",
    "\n",
    "# These are hyperparameters we may want to tune, as they can affect the model training success:\n",
    "hyperparameters={\n",
    "    **base_hyperparameters, \n",
    "    **dict(\n",
    "        learning_rate=0.001,\n",
    "        mini_batch_size=5,\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "image_classifier.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-08 12:29:50 Starting - Starting the training job...\n",
      "2019-09-08 12:29:51 Starting - Launching requested ML instances...\n",
      "2019-09-08 12:30:47 Starting - Preparing the instances for training......\n",
      "2019-09-08 12:31:49 Downloading - Downloading input data......\n",
      "2019-09-08 12:32:21 Training - Downloading the training image......\n",
      "2019-09-08 12:33:46 Training - Training image download completed. Training in progress..\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'0.001', u'num_training_samples': u'63', u'image_shape': u'3,224,224', u'mini_batch_size': u'5', u'use_pretrained_model': u'1', u'num_classes': u'4'}\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] Final configuration: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': u'1', u'num_classes': u'4', u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': u'5', u'weight_decay': 0.0001, u'learning_rate': u'0.001', u'momentum': 0, u'num_training_samples': u'63'}\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] Searching for .rec files in /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] Searching for .rec files in /opt/ml/input/data/validation.\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] multi_label: 0\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] ---- Parameters ----\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] num_layers: 152\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] epochs: 30\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] optimizer: sgd\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] momentum: 0.9\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] learning_rate: 0.001\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] num_training_samples: 63\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] mini_batch_size: 5\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] num_classes: 4\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] augmentation_type: None\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] kv_store: device\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:48 INFO 140088562734912] --------------------\u001b[0m\n",
      "\u001b[31m[12:33:48] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-master.883.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[31m[12:33:48] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-master.883.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:33:50 INFO 140088562734912] Setting number of threads: 3\u001b[0m\n",
      "\u001b[31m[12:33:55] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-master.883.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:08 INFO 140088562734912] Epoch[0] Train-accuracy=0.550000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:08 INFO 140088562734912] Epoch[0] Time cost=13.545\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:08 INFO 140088562734912] Epoch[0] Validation-accuracy=0.840000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:09 INFO 140088562734912] Storing the best model with validation accuracy: 0.840000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:10 INFO 140088562734912] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:15 INFO 140088562734912] Epoch[1] Train-accuracy=0.866667\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:15 INFO 140088562734912] Epoch[1] Time cost=4.899\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:16 INFO 140088562734912] Epoch[1] Validation-accuracy=0.900000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:16 INFO 140088562734912] Storing the best model with validation accuracy: 0.900000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:17 INFO 140088562734912] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:22 INFO 140088562734912] Epoch[2] Train-accuracy=0.933333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:22 INFO 140088562734912] Epoch[2] Time cost=4.768\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:22 INFO 140088562734912] Epoch[2] Validation-accuracy=0.960000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:23 INFO 140088562734912] Storing the best model with validation accuracy: 0.960000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:24 INFO 140088562734912] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:28 INFO 140088562734912] Epoch[3] Train-accuracy=0.883333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:28 INFO 140088562734912] Epoch[3] Time cost=4.748\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:29 INFO 140088562734912] Epoch[3] Validation-accuracy=0.960000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:35 INFO 140088562734912] Epoch[4] Train-accuracy=0.916667\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:35 INFO 140088562734912] Epoch[4] Time cost=4.875\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:36 INFO 140088562734912] Epoch[4] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:37 INFO 140088562734912] Storing the best model with validation accuracy: 1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:37 INFO 140088562734912] Saved checkpoint to \"/opt/ml/model/image-classification-0005.params\"\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:42 INFO 140088562734912] Epoch[5] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:42 INFO 140088562734912] Epoch[5] Time cost=4.770\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:43 INFO 140088562734912] Epoch[5] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:49 INFO 140088562734912] Epoch[6] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:49 INFO 140088562734912] Epoch[6] Time cost=4.827\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:50 INFO 140088562734912] Epoch[6] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:55 INFO 140088562734912] Epoch[7] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:55 INFO 140088562734912] Epoch[7] Time cost=4.829\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:34:56 INFO 140088562734912] Epoch[7] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:02 INFO 140088562734912] Epoch[8] Train-accuracy=0.966667\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:02 INFO 140088562734912] Epoch[8] Time cost=4.822\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:03 INFO 140088562734912] Epoch[8] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:09 INFO 140088562734912] Epoch[9] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:09 INFO 140088562734912] Epoch[9] Time cost=4.974\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:10 INFO 140088562734912] Epoch[9] Validation-accuracy=0.933333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:15 INFO 140088562734912] Epoch[10] Train-accuracy=0.933333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:15 INFO 140088562734912] Epoch[10] Time cost=4.842\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:16 INFO 140088562734912] Epoch[10] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:22 INFO 140088562734912] Epoch[11] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:22 INFO 140088562734912] Epoch[11] Time cost=4.801\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:23 INFO 140088562734912] Epoch[11] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:29 INFO 140088562734912] Epoch[12] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:29 INFO 140088562734912] Epoch[12] Time cost=4.838\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:30 INFO 140088562734912] Epoch[12] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:36 INFO 140088562734912] Epoch[13] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:36 INFO 140088562734912] Epoch[13] Time cost=4.862\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:36 INFO 140088562734912] Epoch[13] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:42 INFO 140088562734912] Epoch[14] Train-accuracy=0.966667\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:42 INFO 140088562734912] Epoch[14] Time cost=4.942\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:43 INFO 140088562734912] Epoch[14] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:49 INFO 140088562734912] Epoch[15] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:49 INFO 140088562734912] Epoch[15] Time cost=4.848\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:50 INFO 140088562734912] Epoch[15] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:56 INFO 140088562734912] Epoch[16] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:56 INFO 140088562734912] Epoch[16] Time cost=4.852\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:35:57 INFO 140088562734912] Epoch[16] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:03 INFO 140088562734912] Epoch[17] Train-accuracy=0.966667\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:03 INFO 140088562734912] Epoch[17] Time cost=4.863\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:03 INFO 140088562734912] Epoch[17] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:09 INFO 140088562734912] Epoch[18] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:09 INFO 140088562734912] Epoch[18] Time cost=4.871\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:10 INFO 140088562734912] Epoch[18] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:16 INFO 140088562734912] Epoch[19] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:16 INFO 140088562734912] Epoch[19] Time cost=4.947\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:17 INFO 140088562734912] Epoch[19] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:23 INFO 140088562734912] Epoch[20] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:23 INFO 140088562734912] Epoch[20] Time cost=4.855\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:24 INFO 140088562734912] Epoch[20] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:29 INFO 140088562734912] Epoch[21] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:29 INFO 140088562734912] Epoch[21] Time cost=4.863\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:30 INFO 140088562734912] Epoch[21] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:36 INFO 140088562734912] Epoch[22] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:36 INFO 140088562734912] Epoch[22] Time cost=4.864\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:37 INFO 140088562734912] Epoch[22] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:43 INFO 140088562734912] Epoch[23] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:43 INFO 140088562734912] Epoch[23] Time cost=4.849\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:44 INFO 140088562734912] Epoch[23] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:50 INFO 140088562734912] Epoch[24] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:50 INFO 140088562734912] Epoch[24] Time cost=4.950\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:51 INFO 140088562734912] Epoch[24] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:57 INFO 140088562734912] Epoch[25] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:57 INFO 140088562734912] Epoch[25] Time cost=4.897\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:36:57 INFO 140088562734912] Epoch[25] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:03 INFO 140088562734912] Epoch[26] Train-accuracy=0.966667\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:03 INFO 140088562734912] Epoch[26] Time cost=4.892\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:04 INFO 140088562734912] Epoch[26] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:10 INFO 140088562734912] Epoch[27] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:10 INFO 140088562734912] Epoch[27] Time cost=4.864\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:11 INFO 140088562734912] Epoch[27] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:17 INFO 140088562734912] Epoch[28] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:17 INFO 140088562734912] Epoch[28] Time cost=4.827\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:18 INFO 140088562734912] Epoch[28] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:23 INFO 140088562734912] Epoch[29] Train-accuracy=0.933333\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:23 INFO 140088562734912] Epoch[29] Time cost=4.872\u001b[0m\n",
      "\u001b[31m[09/08/2019 12:37:24 INFO 140088562734912] Epoch[29] Validation-accuracy=1.000000\u001b[0m\n",
      "\n",
      "2019-09-08 12:37:29 Uploading - Uploading generated training model\n",
      "2019-09-08 12:38:00 Completed - Training job completed\n",
      "Training seconds: 371\n",
      "Billable seconds: 371\n",
      "\n",
      "\n",
      " Finished training! The model is available for download at: s3://sagemaker-us-east-2-425359244402/FinalData/output/IC-FinalData-1567945789/output/model.tar.gz\n",
      "CPU times: user 6.1 s, sys: 0 ns, total: 6.1 s\n",
      "Wall time: 8min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "now = str(int(time.time()))\n",
    "training_job_name = 'IC-' + dataset_name.replace('_', '-') + '-' + now\n",
    "\n",
    "image_classifier.fit(inputs=data_channels, job_name=training_job_name, logs=True)\n",
    "\n",
    "job = image_classifier.latest_training_job\n",
    "model_path = f\"{base_dir}/{job.name}\"\n",
    "\n",
    "print(f\"\\n\\n Finished training! The model is available for download at: {image_classifier.output_path}/{job.name}/output/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------------------------------!CPU times: user 6.54 s, sys: 0 ns, total: 6.54 s\n",
      "Wall time: 10min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Deploying a model to an endpoint takes a few minutes to complete\n",
    "\n",
    "deployed_endpoint = image_classifier.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.t2.medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def classify_deployed(file_name, classes):\n",
    "    payload = None\n",
    "    with open(file_name, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "\n",
    "    deployed_endpoint.content_type = 'application/x-image'\n",
    "    result = json.loads(deployed_endpoint.predict(payload))\n",
    "    best_prob_index = np.argmax(result)    \n",
    "    if (result[best_prob_index] > 0.9): \n",
    "        if best_prob_index == 0: \n",
    "            return 'c'\n",
    "        id best_prob_index == 1: \n",
    "            return 'r'\n",
    "\n",
    "def classify_frame(f, classes): \n",
    "  \n",
    "    \n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "\n",
    "    deployed_endpoint.content_type = 'application/x-image'\n",
    "    result = json.loads(deployed_endpoint.predict(payload))\n",
    "    best_prob_index = np.argmax(result)        \n",
    "    print(dataset_name, result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FinalData [0.48831528425216675, 0.20727819204330444, 0.19341452419757843, 0.11099204421043396]\n",
      "[master fb9a064] asdf\n",
      " Committer: EC2 Default User <ec2-user@ip-172-16-78-8.us-east-2.compute.internal>\n",
      "Your name and email address were configured automatically based\n",
      "on your username and hostname. Please check that they are accurate.\n",
      "You can suppress this message by setting them explicitly:\n",
      "\n",
      "    git config --global user.name \"Your Name\"\n",
      "    git config --global user.email you@example.com\n",
      "\n",
      "After doing this, you may fix the identity used for this commit with:\n",
      "\n",
      "    git commit --amend --reset-author\n",
      "\n",
      " 1 file changed, 1 insertion(+)\n",
      "fatal: remote origin already exists.\n",
      "Username for 'https://github.com/alexander-edwards/PennPics': "
     ]
    }
   ],
   "source": [
    "import time \n",
    "while (True): \n",
    "    to_write = classify_deployed('picture.jpg', dataset_name) \n",
    "    !echo to_write >> instruc.txt\n",
    "    !git add *\n",
    "    !git commit -m 'asdf'\n",
    "    !git remote add origin https://github.com/alexander-edwards/PennPics\n",
    "    !git push origin master\n",
    "    !git init\n",
    "    !git clean -d -f\n",
    "    !git pull https://github.com/alexander-edwards/PennPics\n",
    "    time.sleep(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfasdfasdfas.jpg  cam.py     PennPics     PLASE.jpg  Untitled Folder\n",
      "asdfasd.jpg\t    fffff.jpg  picture.jpg  test.jpg   Untitled.ipynb\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin\tdev   include  local\t   mnt\t root  selinux\ttmp\n",
      "boot\tetc   lib      lost+found  opt\t run   srv\tusr\n",
      "cgroup\thome  lib64    media\t   proc  sbin  sys\tvar\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdfasdfasdfas.jpg  cam.py     PennPics     PLASE.jpg  Untitled Folder\n",
      "asdfasd.jpg\t    fffff.jpg  picture.jpg  test.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in /home/ec2-user/SageMaker/.git/\n",
      "Skipping repository PennPics/\n",
      "Skipping repository Untitled Folder/Untitled Folder/PennPics\n",
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 16 (delta 5), reused 12 (delta 1), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (16/16), done.\n",
      "From https://github.com/alexander-edwards/PennPics\n",
      " * branch            HEAD       -> FETCH_HEAD\n",
      "Updating fcff815..a217bb0\n",
      "Fast-forward\n",
      " cam.py      |  28 \u001b[32m++++++++++++++++++++++++++++\u001b[m\n",
      " picture.jpg | Bin \u001b[31m0\u001b[m -> \u001b[32m248616\u001b[m bytes\n",
      " 2 files changed, 28 insertions(+)\n",
      " create mode 100644 cam.py\n",
      " create mode 100644 picture.jpg\n"
     ]
    }
   ],
   "source": [
    "!git init\n",
    "!git clean -d -f\n",
    "!git pull https://github.com/alexander-edwards/PennPics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx in /usr/local/lib/python3.6/site-packages (1.1)\n",
      "\u001b[33mYou are using pip version 19.0.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyttsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-232-cc7172034e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sudo pip3 install pyttsx --user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyttsx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyttsx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Good morning.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunAndWait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyttsx'"
     ]
    }
   ],
   "source": [
    "!sudo pip3 install pyttsx --user\n",
    "import pyttsx\n",
    "engine = pyttsx.init()\n",
    "engine.say('Good morning.')\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Downloading https://files.pythonhosted.org/packages/02/0b/e19dd65623e34954fb6793765ad1c6185a669a33e6a6245939e97abeaaca/gTTS-2.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gtts) (1.11.0)\n",
      "Collecting gtts-token>=1.1.3 (from gtts)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/25/ca6e9cd3275bfc3097fe6b06cc31db6d3dfaf32e032e0f73fead9c9a03ce/gTTS-token-1.1.3.tar.gz\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gtts) (6.7)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gtts) (2.20.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gtts) (4.6.0)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->gtts) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->gtts) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->gtts) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->gtts) (3.0.4)\n",
      "Building wheels for collected packages: gtts-token\n",
      "  Building wheel for gtts-token (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gtts-token: filename=gTTS_token-1.1.3-cp36-none-any.whl size=3273 sha256=a7280a557e90bd533c70631014a905b556a333688ed248e7dac0516e7396a3f7\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/dd/11/61/33f7e51bf545e910552b2255eead2a7cd8ef54064b46dceb34\n",
      "Successfully built gtts-token\n",
      "Installing collected packages: gtts-token, gtts\n",
      "Successfully installed gtts-2.0.4 gtts-token-1.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyglet.media.player.Player at 0x7fa48e5145f8>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "import os \n",
    "import pyglet\n",
    "\n",
    "a = gTTS(\"hello\", lang = 'en')\n",
    "a.save('a.mp3')\n",
    "os.system(\"a.mp3\") \n",
    "\n",
    "music = pyglet.media.load('a.mp3', streaming=True)\n",
    "music.play()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyglet\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/0b/73f209f2b367685302c381284a4b57c2f5d87b9002ca352ed9ad5953944d/pyglet-1.4.3-py2.py3-none-any.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pyglet) (0.17.1)\n",
      "Installing collected packages: pyglet\n",
      "Successfully installed pyglet-1.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyserial\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/e4/2a744dd9e3be04a0c0907414e2a01a7c88bb3915cbe3c8cc06e209f59c30/pyserial-3.4-py2.py3-none-any.whl (193kB)\n",
      "\u001b[K     |████████████████████████████████| 194kB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyserial\n",
      "Successfully installed pyserial-3.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pyserial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "SerialException",
     "evalue": "[Errno 2] could not open port /dev/tty.usbmodem143101: [Errno 2] No such file or directory: '/dev/tty.usbmodem143101'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/serial/serialposix.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mportstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO_RDWR\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO_NOCTTY\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO_NONBLOCK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/dev/tty.usbmodem143101'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSerialException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-283-4674c33c8cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0marduino\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/dev/tty.usbmodem143101'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaudrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m9600\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/serial/serialutil.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, port, baudrate, bytesize, parity, stopbits, timeout, xonxoff, rtscts, write_timeout, dsrdtr, inter_byte_timeout, exclusive, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;31m#  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -  -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/serial/serialposix.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mSerialException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"could not open port {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;31m#~ fcntl.fcntl(self.fd, fcntl.F_SETFL, 0)  # set blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSerialException\u001b[0m: [Errno 2] could not open port /dev/tty.usbmodem143101: [Errno 2] No such file or directory: '/dev/tty.usbmodem143101'"
     ]
    }
   ],
   "source": [
    "import serial\n",
    "\n",
    "arduino = serial.Serial('/dev/tty.usbmodem143101', baudrate = 9600, timeout = 1)\n",
    "\n",
    "def getValues():\n",
    "    \n",
    "    arduino.write(b'g')\n",
    "    arduinoData = arduino.readline().decode('ascii')\n",
    "    return arduinoData\n",
    "\n",
    "while(1):\n",
    "    arduino.flush()\n",
    "    #This is going to come from Alex's code\n",
    "    userInput = input('r, c, or t?')\n",
    "    # \"take this input from\"\n",
    "    if userInput == 'r':\n",
    "        print('python sent r')\n",
    "        # \"this is recycable\"\n",
    "        arduino.write(b'r')\n",
    "    elif userInput == 't':\n",
    "\n",
    "        print('python sent t')\n",
    "        # \"this is trash\"\n",
    "        arduino.write(b't')\n",
    "    elif userInput == 'c':\n",
    "\n",
    "        # \"this is compost\"\n",
    "        print('python sent c')\n",
    "        arduino.write(b'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.mp3\t\t    cam.py     picture.jpg  Untitled Folder\n",
      "asdfasdfasdfas.jpg  fffff.jpg  PLASE.jpg    Untitled.ipynb\n",
      "asdfasd.jpg\t    PennPics   test.jpg\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
